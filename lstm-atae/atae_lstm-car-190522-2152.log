n_trainable_params: 2526004, n_nontrainable_params: 1389000
> training arguments:
>>> model_name: atae_lstm
>>> dataset: car
>>> optimizer: <class 'torch.optim.adam.Adam'>
>>> initializer: <function xavier_uniform_ at 0x118371840>
>>> learning_rate: 2e-05
>>> dropout: 0.2
>>> l2reg: 0.01
>>> num_epoch: 10
>>> batch_size: 64
>>> log_step: 5
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 4
>>> hops: 3
>>> device: cpu
>>> seed: None
>>> valset_ratio: 0
>>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>
>>> dataset_file: {'train': './datasets/semeval14/Car_Train.xml.seg', 'test': './datasets/semeval14/Car_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices', 'aspect_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.2955, acc: 0.4156
loss: 1.2905, acc: 0.4188
loss: 1.2827, acc: 0.4323
loss: 1.2772, acc: 0.4313
loss: 1.2681, acc: 0.4537
loss: 1.2659, acc: 0.4536
loss: 1.2594, acc: 0.4705
loss: 1.2532, acc: 0.4836
> val_acc: 0.5600, val_f1: 0.4047
>> saved: state_dict/atae_lstm_car_val_acc0.56
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 1.2284, acc: 0.5312
loss: 1.2132, acc: 0.5417
loss: 1.1994, acc: 0.5611
loss: 1.1911, acc: 0.5693
loss: 1.1853, acc: 0.5699
loss: 1.1723, acc: 0.5799
loss: 1.1698, acc: 0.5852
loss: 1.1660, acc: 0.5829
loss: 1.1624, acc: 0.5819
> val_acc: 0.5689, val_f1: 0.4188
>> saved: state_dict/atae_lstm_car_val_acc0.5689
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 1.1176, acc: 0.5547
loss: 1.1040, acc: 0.5893
loss: 1.1107, acc: 0.5794
loss: 1.1043, acc: 0.5882
loss: 1.1134, acc: 0.5703
loss: 1.1054, acc: 0.5741
loss: 1.1003, acc: 0.5684
loss: 1.0956, acc: 0.5659
loss: 1.0937, acc: 0.5636
> val_acc: 0.5422, val_f1: 0.3957
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 1.0494, acc: 0.5625
loss: 1.0497, acc: 0.5566
loss: 1.0538, acc: 0.5493
loss: 1.0539, acc: 0.5408
loss: 1.0518, acc: 0.5387
loss: 1.0539, acc: 0.5413
loss: 1.0453, acc: 0.5436
loss: 1.0383, acc: 0.5432
loss: 1.0326, acc: 0.5512
> val_acc: 0.5541, val_f1: 0.4051
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 0.9659, acc: 0.5820
loss: 0.9905, acc: 0.5764
loss: 1.0078, acc: 0.5614
loss: 0.9913, acc: 0.5641
loss: 0.9951, acc: 0.5586
loss: 0.9910, acc: 0.5630
loss: 0.9905, acc: 0.5630
loss: 0.9951, acc: 0.5617
loss: 0.9970, acc: 0.5609
> val_acc: 0.5600, val_f1: 0.4118
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 0.9325, acc: 0.5750
loss: 0.9561, acc: 0.5563
loss: 0.9965, acc: 0.5365
loss: 0.9821, acc: 0.5477
loss: 0.9789, acc: 0.5563
loss: 0.9762, acc: 0.5594
loss: 0.9774, acc: 0.5629
loss: 0.9781, acc: 0.5613
> val_acc: 0.5541, val_f1: 0.4086
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 1.0022, acc: 0.5625
loss: 0.9499, acc: 0.5859
loss: 0.9627, acc: 0.5696
loss: 0.9547, acc: 0.5732
loss: 0.9700, acc: 0.5610
loss: 0.9794, acc: 0.5559
loss: 0.9727, acc: 0.5559
loss: 0.9666, acc: 0.5595
loss: 0.9684, acc: 0.5617
