n_trainable_params: 2526004, n_nontrainable_params: 1389000
> training arguments:
>>> model_name: atae_lstm
>>> dataset: car
>>> optimizer: <class 'torch.optim.adagrad.Adagrad'>
>>> initializer: <function orthogonal_ at 0x1231d6bf8>
>>> learning_rate: 2e-05
>>> dropout: 0.05
>>> l2reg: 0.01
>>> num_epoch: 10
>>> batch_size: 64
>>> log_step: 5
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 4
>>> hops: 3
>>> device: cpu
>>> seed: None
>>> valset_ratio: 0
>>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>
>>> dataset_file: {'train': './datasets/semeval14/Car_Train.xml.seg', 'test': './datasets/semeval14/Car_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices', 'aspect_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.4047, acc: 0.0781
loss: 1.4061, acc: 0.0797
n_trainable_params: 2526004, n_nontrainable_params: 1389000
> training arguments:
>>> model_name: atae_lstm
>>> dataset: car
>>> optimizer: <class 'torch.optim.adadelta.Adadelta'>
>>> initializer: <function xavier_uniform_ at 0x11dddd840>
>>> learning_rate: 2e-05
>>> dropout: 0.05
>>> l2reg: 0.01
>>> num_epoch: 10
>>> batch_size: 64
>>> log_step: 5
>>> embed_dim: 300
>>> hidden_dim: 300
>>> bert_dim: 768
>>> pretrained_bert_name: bert-base-uncased
>>> max_seq_len: 80
>>> polarities_dim: 4
>>> hops: 3
>>> device: cpu
>>> seed: None
>>> valset_ratio: 0
>>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>
>>> dataset_file: {'train': './datasets/semeval14/Car_Train.xml.seg', 'test': './datasets/semeval14/Car_Test_Gold.xml.seg'}
>>> inputs_cols: ['text_raw_indices', 'aspect_indices']
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 0
loss: 1.3281, acc: 0.4156
loss: 1.3190, acc: 0.4453
loss: 1.3230, acc: 0.4385
loss: 1.3207, acc: 0.4414
loss: 1.3222, acc: 0.4313
loss: 1.3257, acc: 0.4182
loss: 1.3257, acc: 0.4165
loss: 1.3265, acc: 0.4152
> val_acc: 0.4222, val_f1: 0.2100
>> saved: state_dict/atae_lstm_car_val_acc0.4222
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 1
loss: 1.3216, acc: 0.4219
loss: 1.3265, acc: 0.4141
loss: 1.3298, acc: 0.4034
loss: 1.3298, acc: 0.3994
loss: 1.3269, acc: 0.4048
loss: 1.3269, acc: 0.4069
loss: 1.3259, acc: 0.4128
loss: 1.3269, acc: 0.4119
loss: 1.3266, acc: 0.4139
> val_acc: 0.4222, val_f1: 0.2100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 2
loss: 1.3319, acc: 0.3828
loss: 1.3169, acc: 0.4442
loss: 1.3254, acc: 0.4180
loss: 1.3254, acc: 0.4136
loss: 1.3231, acc: 0.4126
loss: 1.3269, acc: 0.4062
loss: 1.3256, acc: 0.4106
loss: 1.3254, acc: 0.4126
loss: 1.3258, acc: 0.4137
> val_acc: 0.4222, val_f1: 0.2100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 3
loss: 1.3289, acc: 0.3698
loss: 1.3246, acc: 0.3926
loss: 1.3248, acc: 0.4075
loss: 1.3265, acc: 0.4045
loss: 1.3248, acc: 0.4117
loss: 1.3272, acc: 0.4079
loss: 1.3255, acc: 0.4134
loss: 1.3256, acc: 0.4157
loss: 1.3260, acc: 0.4139
> val_acc: 0.4222, val_f1: 0.2100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 4
loss: 1.3201, acc: 0.4297
loss: 1.3300, acc: 0.3924
loss: 1.3323, acc: 0.3940
loss: 1.3355, acc: 0.3865
loss: 1.3310, acc: 0.4004
loss: 1.3283, acc: 0.4073
loss: 1.3261, acc: 0.4136
loss: 1.3251, acc: 0.4159
loss: 1.3252, acc: 0.4149
> val_acc: 0.4222, val_f1: 0.2100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 5
loss: 1.3292, acc: 0.3906
loss: 1.3312, acc: 0.3891
loss: 1.3330, acc: 0.3844
loss: 1.3291, acc: 0.4000
loss: 1.3290, acc: 0.4000
loss: 1.3285, acc: 0.4052
loss: 1.3267, acc: 0.4089
loss: 1.3249, acc: 0.4145
> val_acc: 0.4222, val_f1: 0.2100
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
epoch: 6
loss: 1.2842, acc: 0.5000
loss: 1.3123, acc: 0.4297
loss: 1.3178, acc: 0.4233
